# -*- coding: utf-8 -*-
"""sound_sentiment_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-w1e52yCDWGgFYd2Z6zhIvNAtUcqJQjh
"""

from google.colab import drive
drive.mount('/content/drive')

!cp '/content/drive/MyDrive/sound_sentimen/train (1).csv' '/content/train.csv'
!cp '/content/drive/MyDrive/sound_sentimen/train (2).zip' '/content/train.zip'
!cp '/content/drive/MyDrive/sound_sentimen/val (2).zip' '/content/val.zip'
!cp '/content/drive/MyDrive/sound_sentimen/val.csv' '/content/val.csv'

!unzip '/content/train.zip'
!unzip '/content/val.zip'

import librosa
import soundfile
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
from tqdm import tqdm
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

def extract_feature(file_name):
    
    with soundfile.SoundFile(file_name) as sound_file:
        X = sound_file.read(dtype="float32")
        sample_rate = sound_file.samplerate
        result = np.array([])
        mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)
        result = np.hstack((result,mfccs))
        stft = np.abs(librosa.stft(X))
        chroma = np.mean(librosa.feature.chroma_stft(S=stft,sr=sample_rate).T,axis=0)
        result = np.hstack((result,chroma))
        mel = np.mean(librosa.feature.melspectrogram(X,sr=sample_rate).T,axis=0)
        result = np.hstack((result,mel))
    return result
    #180 dimensional row (40+12+128)

def load_data(file_path,label_path,test_bool=False):
    x,y=[],[]
    if test_bool==False:
      data = pd.read_csv(os.path.join(label_path))
    for file in tqdm(os.listdir(file_path)):
        file_name = os.path.join(file_path + file)
        label_name = file.split('.')[0]
        features = extract_feature(file_name)
        x.append(features)
        if test_bool==False:
          label = data.loc[data['wav_id']==int(label_name),'label']
          y.append(label)
    
    if test_bool==False:
      return np.array(x),np.array(y)
    else:
      return np.array(x)

train_path = '/content/train/'
train_file = '/content/train.csv'
X_train,Y_train = load_data(train_path,train_file)
print(X_train.shape)
print(Y_train.shape)

val_path = '/content/val/'
val_file = '/content/val.csv'
X_val,Y_val = load_data(val_path,val_file)
print(X_val.shape)
print(Y_val.shape)

from sklearn.ensemble import RandomForestClassifier
weights = {0:4.288, 1:4.263, 2:0.395}
model = RandomForestClassifier(n_estimators=1000, class_weight=weights)

del history
history = model.fit(X_train,Y_train)

print(history)

import pickle
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))

print(Y_train[0])
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

enc = OneHotEncoder(sparse=False)  #use sparse=False or else weird output comes
Y_enc_train = enc.fit_transform(Y_train)
print(Y_enc_train[0])
print(Y_enc_train.shape)

Y_enc_val = enc.transform(Y_val)
print(Y_enc_val[0])
print(Y_enc_val.shape)

# model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)

import keras
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.layers import Dropout

model = Sequential()
model.add(Dense(550,input_dim=180,activation='sigmoid'))
model.add(Dropout(0.2))
model.add(Dense(350,activation='sigmoid'))
model.add(Dropout(0.2))
model.add(Dense(50,activation='sigmoid'))
model.add(Dropout(0.2))
model.add(Dense(3,activation='softmax'))
model.summary()

from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json)
# load weights into new model
model.load_weights("model.h5")
print("Loaded model from disk")

model.summary()

from keras.optimizers import SGD
opt = SGD(lr=0.0001, momentum=0.9)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

weights = {0:4.288, 1:4.263, 2:0.395}
#500epochs
history = model.fit(X_train, Y_enc_train,class_weight=weights,epochs=700,batch_size=32,verbose=1,validation_data=(X_val,Y_enc_val))

print(history.history.keys())

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

Y_val_pred=model.predict(X_val)
#Y_val_pre_arg = np.argmax(Y_val_pred,axis=1)  Remove for dl
print(Y_val_pred[0:5])
#print(Y_val_pre_arg[0:5])

#accuracy=accuracy_score(y_true=Y_val, y_pred=Y_val_pre_arg) Remove for DL

accuracy=accuracy_score(y_true=Y_val, y_pred=Y_val_pred) 

#DataFlair - Print the accuracy
print("Accuracy: {:.2f}%".format(accuracy*100))

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
def evaluate_model(X, y, model):
	# define evaluation procedure
	cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)
	# evaluate model
	scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
	return scores

scores = evaluate_model(X_val, Y_val, model)
# summarize performance

from numpy import mean
from numpy import std
print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

!cp '/content/drive/MyDrive/sound_sentimen/test (1).zip' '/content/test.zip'
!unzip '/content/test.zip'

test_path = '/content/test/'
X_test = load_data(test_path,None,True)
print(X_test.shape)

df = pd.DataFrame(columns=['wav_id', 'label'])

Y_test_pred=model.predict(X_test)
#Y_test_pre_arg = np.argmax(Y_test_pred,axis=1) Remove for DL
print(Y_test_pred[0:5])
#print(Y_test_pre_arg.shape)

for i,y in tqdm(enumerate(Y_test_pred)):
  df = df.append({'wav_id':i,'label':y},ignore_index=True)
print(df.head())

df.to_csv("submission.csv", index=False)
try:
    from google.colab import files
    files.download('submission.csv') 
except:
    print("Option Only avilable in Google Colab")

try:
    from google.colab import files
    files.download('/content/finalized_model.sav') 
except:
    print("Option Only avilable in Google Colab")